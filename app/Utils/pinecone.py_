from langchain.schema import Document
import pandas as pd
from fastapi import UploadFile, File
from langchain.document_loaders.csv_loader import CSVLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Pinecone
from dotenv import load_dotenv
import os
import pinecone
import openai
import tiktoken

load_dotenv()
tokenizer = tiktoken.get_encoding('cl100k_base')

pinecone.init(
    api_key=os.getenv('PINECONE_API_KEY'),  # find at app.pinecone.io
    environment=os.getenv('PINECONE_ENV'),  # next to api key in console
)

index_name = os.getenv('PINECONE_INDEX')
embeddings = OpenAIEmbeddings()
similarity_min_value = 0.5


def tiktoken_len(text):
    tokens = tokenizer.encode(
        text,
        disallowed_special=()
    )
    return len(tokens)


# def train_file(filename: str):
    destination_directory = "./app/training-files/"
    destination_file_path = os.path.join(destination_directory, filename)

    loader = CSVLoader(file_path=destination_file_path)
    data = loader.load()
    context = ''
    for d in data:
        context += d.page_content
    doc = Document(page_content=context, metadata={"source": filename})
    text_splitter = CharacterTextSplitter(
        chunk_size=1000, chunk_overlap=0, length_function=tiktoken_len,)
    chunks = text_splitter.split_documents([doc])

    Pinecone.from_documents(
        chunks, embedding=embeddings, index_name=index_name)


def get_answer(msg: str):
    docsearch = Pinecone.from_existing_index(index_name, embeddings)
    docs = docsearch.similarity_search(msg, k=4)
    context = ''
    for doc in docs:
        context += doc.page_content

    instructor = f"""
        Answer questions based on  given context as well as your knowledge.
        If context don't include answer that matches question, kindly reply it doesn't have answer.
        -----------------------
        This is context you can refer to.
        {context}
    """
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            max_tokens=1000,
            messages=[
                {"role": "system", "content": instructor},
                {"role": "user", "content": msg},
            ],
            stream=True
        )
        for chunk in response:
            if 'content' in chunk.choices[0].delta:
                string = chunk.choices[0].delta.content
                yield string
    except Exception as e:
        print("Error in creating campaigns from openAI:")
    # return iter(response.choices[0].message.content)
